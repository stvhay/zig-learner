From fbfc5454c4d8311b6658e0ce2232f110500d327d Mon Sep 17 00:00:00 2001
From: Steve Hay <github@stevenhay.com>
Date: Sat, 21 Feb 2026 00:07:16 -0500
Subject: [PATCH] feat: add rag_batch_search MCP tool for multi-query search

New MCP tool that accepts a list of search queries and returns all
results in a single call. Reduces agent-MCP round-trips from N to 1
by sharing one DB connection and batching all embeddings into a single
Ollama call via get_embeddings().

- BatchQuery dataclass and perform_batch_search() in search.py
- rag_batch_search tool in mcp_server.py with full filter support,
  source URI generation, path mappings, and ACE telemetry logging
- 13 new tests across test_mcp_server.py and test_search.py

Signed-off-by: Steve Hay <github@stevenhay.com>
---
 src/ragling/mcp_server.py | 102 ++++++++++++++++++++
 src/ragling/search.py     |  81 +++++++++++++++-
 tests/test_mcp_server.py  | 190 ++++++++++++++++++++++++++++++++++++++
 tests/test_search.py      |  75 ++++++++++++++-
 4 files changed, 446 insertions(+), 2 deletions(-)

diff --git a/src/ragling/mcp_server.py b/src/ragling/mcp_server.py
index 1e03b02..5c6ed56 100644
--- a/src/ragling/mcp_server.py
+++ b/src/ragling/mcp_server.py
@@ -545,6 +545,108 @@ def create_server(
 
         return _build_search_response(result_dicts, indexing_status)
 
+    @mcp.tool()
+    def rag_batch_search(
+        queries: list[dict[str, Any]],
+    ) -> dict[str, Any]:
+        """Run multiple searches in a single call, returning all results at once.
+
+        This is more efficient than calling rag_search multiple times because it
+        shares one database connection and batches all embedding requests into a
+        single Ollama call.
+
+        Each query in the list accepts the same parameters as rag_search:
+        query (required), collection, top_k, source_type, date_from, date_to,
+        sender, author.
+
+        Example input::
+
+            queries=[
+                {"query": "memory allocator", "collection": "code"},
+                {"query": "error handling patterns", "top_k": 5},
+                {"query": "build system", "collection": "obsidian"}
+            ]
+
+        Args:
+            queries: List of search query dicts. Each must have a "query" key.
+                Other keys match rag_search parameters.
+
+        Returns:
+            Dict with ``results`` (list of per-query result lists, same order as
+            input) and optional ``indexing_status``.
+        """
+        from ragling.embeddings import OllamaConnectionError
+        from ragling.search import BatchQuery, perform_batch_search
+
+        if not queries:
+            return _build_search_response([], indexing_status)
+
+        visible = _get_visible_collections(server_config)
+        user_ctx = _get_user_context(server_config)
+
+        batch_queries = []
+        for q in queries:
+            if not isinstance(q, dict) or "query" not in q:
+                return {"error": "Each query must be a dict with a 'query' key."}
+            batch_queries.append(
+                BatchQuery(
+                    query=q["query"],
+                    collection=q.get("collection"),
+                    top_k=q.get("top_k", 10),
+                    source_type=q.get("source_type"),
+                    date_from=q.get("date_from"),
+                    date_to=q.get("date_to"),
+                    sender=q.get("sender"),
+                    author=q.get("author"),
+                )
+            )
+
+        try:
+            all_results = perform_batch_search(
+                queries=batch_queries,
+                group_name=group_name,
+                config=server_config,
+                visible_collections=visible,
+            )
+        except OllamaConnectionError as e:
+            return _build_search_response([{"error": str(e)}], indexing_status)
+
+        obsidian_vaults = (server_config or load_config()).obsidian_vaults
+
+        all_result_dicts = []
+        for result_list in all_results:
+            result_dicts = [
+                {
+                    "title": r.title,
+                    "content": r.content,
+                    "collection": r.collection,
+                    "source_type": r.source_type,
+                    "source_path": r.source_path,
+                    "source_uri": _build_source_uri(
+                        r.source_path,
+                        r.source_type,
+                        r.metadata,
+                        r.collection,
+                        obsidian_vaults,
+                    ),
+                    "score": round(r.score, 4),
+                    "metadata": r.metadata,
+                    "stale": r.stale,
+                }
+                for r in result_list
+            ]
+            if user_ctx:
+                result_dicts = _apply_user_context_to_results(result_dicts, user_ctx)
+            all_result_dicts.append(result_dicts)
+
+        response: dict[str, Any] = {"results": all_result_dicts}
+        if indexing_status:
+            status_dict = indexing_status.to_dict()
+            response["indexing"] = status_dict if status_dict and status_dict.get("active") else None
+        else:
+            response["indexing"] = None
+        return response
+
     @mcp.tool()
     def rag_list_collections() -> dict[str, Any]:
         """List all available collections with source file counts, chunk counts, and metadata.
diff --git a/src/ragling/search.py b/src/ragling/search.py
index 85b4cf8..b8cea35 100644
--- a/src/ragling/search.py
+++ b/src/ragling/search.py
@@ -9,7 +9,7 @@ from datetime import datetime, timezone
 
 from ragling.config import Config, load_config
 from ragling.db import get_connection, init_db
-from ragling.embeddings import get_embedding, serialize_float32
+from ragling.embeddings import get_embedding, get_embeddings, serialize_float32
 from ragling.search_utils import escape_fts_query
 
 logger = logging.getLogger(__name__)
@@ -490,3 +490,82 @@ def perform_search(
         )
     finally:
         conn.close()
+
+
+@dataclass
+class BatchQuery:
+    """A single query within a batch search request."""
+
+    query: str
+    collection: str | None = None
+    top_k: int = 10
+    source_type: str | None = None
+    date_from: str | None = None
+    date_to: str | None = None
+    sender: str | None = None
+    author: str | None = None
+
+
+def perform_batch_search(
+    queries: list[BatchQuery],
+    group_name: str = "default",
+    config: Config | None = None,
+    visible_collections: list[str] | None = None,
+) -> list[list[SearchResult]]:
+    """Run multiple searches sharing one DB connection and one embedding call.
+
+    Args:
+        queries: List of BatchQuery objects.
+        group_name: Group name for per-group indexes.
+        config: Optional pre-loaded Config.
+        visible_collections: Optional collection visibility filter.
+
+    Returns:
+        List of result lists, one per query in the same order.
+
+    Raises:
+        ragling.embeddings.OllamaConnectionError: If Ollama is not reachable.
+    """
+    if not queries:
+        return []
+
+    config = (config or load_config()).with_overrides(group_name=group_name)
+    conn = get_connection(config)
+    init_db(conn, config)
+
+    try:
+        query_texts = [q.query for q in queries]
+        all_embeddings = get_embeddings(query_texts, config)
+
+        for emb in all_embeddings:
+            if len(emb) != config.embedding_dimensions:
+                raise ValueError(
+                    f"embedding dimension mismatch: got {len(emb)}, "
+                    f"expected {config.embedding_dimensions}"
+                )
+
+        results: list[list[SearchResult]] = []
+        for q, embedding in zip(queries, all_embeddings):
+            filters = SearchFilters(
+                collection=q.collection,
+                source_type=q.source_type,
+                date_from=q.date_from,
+                date_to=q.date_to,
+                sender=q.sender,
+                author=q.author,
+            )
+            results.append(
+                search(
+                    conn,
+                    embedding,
+                    q.query,
+                    q.top_k,
+                    filters,
+                    config,
+                    visible_collections=visible_collections,
+                )
+            )
+
+        return results
+    finally:
+        conn.close()
diff --git a/tests/test_mcp_server.py b/tests/test_mcp_server.py
index bd19e6f..6ced3ca 100644
--- a/tests/test_mcp_server.py
+++ b/tests/test_mcp_server.py
@@ -1148,3 +1148,193 @@ class TestRagIndexingStatus:
         result = fn()
 
         assert result == {"active": False}
+
+
+class TestRagBatchSearch:
+    """Tests for the rag_batch_search MCP tool."""
+
+    def test_batch_search_registered(self, tmp_path: Path) -> None:
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        server = create_server(config=config)
+        tools = server._tool_manager._tools
+        assert "rag_batch_search" in tools
+
+    def test_batch_search_empty_queries(self, tmp_path: Path) -> None:
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        server = create_server(config=config)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        result = fn(queries=[])
+        assert result["results"] == []
+        assert result["indexing"] is None
+
+    def test_batch_search_rejects_missing_query_key(self, tmp_path: Path) -> None:
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        server = create_server(config=config)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        result = fn(queries=[{"collection": "obsidian"}])
+        assert "error" in result
+
+    def test_batch_search_calls_perform_batch_search(self, tmp_path: Path) -> None:
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        server = create_server(config=config)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        with patch("ragling.search.perform_batch_search", return_value=[[], []]) as mock_pbs:
+            result = fn(queries=[
+                {"query": "hello"},
+                {"query": "world", "collection": "code", "top_k": 5},
+            ])
+
+        mock_pbs.assert_called_once()
+        call_args = mock_pbs.call_args
+        batch_queries = call_args.kwargs["queries"]
+        assert len(batch_queries) == 2
+        assert batch_queries[0].query == "hello"
+        assert batch_queries[0].top_k == 10  # default
+        assert batch_queries[1].query == "world"
+        assert batch_queries[1].collection == "code"
+        assert batch_queries[1].top_k == 5
+        assert result["results"] == [[], []]
+
+    def test_batch_search_returns_per_query_results(self, tmp_path: Path) -> None:
+        from ragling.mcp_server import create_server
+        from ragling.search import SearchResult
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        server = create_server(config=config)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        mock_results = [
+            [
+                SearchResult(
+                    content="result 1",
+                    title="Result 1",
+                    metadata={},
+                    score=0.9,
+                    collection="code",
+                    source_path="/tmp/a.py",
+                    source_type="code",
+                ),
+            ],
+            [
+                SearchResult(
+                    content="result 2",
+                    title="Result 2",
+                    metadata={},
+                    score=0.8,
+                    collection="obsidian",
+                    source_path="/tmp/b.md",
+                    source_type="markdown",
+                ),
+            ],
+        ]
+
+        with patch("ragling.search.perform_batch_search", return_value=mock_results):
+            result = fn(queries=[
+                {"query": "first"},
+                {"query": "second"},
+            ])
+
+        assert len(result["results"]) == 2
+        assert len(result["results"][0]) == 1
+        assert result["results"][0][0]["title"] == "Result 1"
+        assert len(result["results"][1]) == 1
+        assert result["results"][1][0]["title"] == "Result 2"
+
+    def test_batch_search_handles_ollama_error(self, tmp_path: Path) -> None:
+        from ragling.embeddings import OllamaConnectionError
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        server = create_server(config=config)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        with patch(
+            "ragling.search.perform_batch_search",
+            side_effect=OllamaConnectionError("connection refused"),
+        ):
+            result = fn(queries=[{"query": "test"}])
+
+        assert result["results"][0]["error"] == "connection refused"
+
+    def test_batch_search_includes_indexing_status(self, tmp_path: Path) -> None:
+        from ragling.indexing_status import IndexingStatus
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        status = IndexingStatus()
+        status.increment("obsidian", 3)
+        server = create_server(config=config, indexing_status=status)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        with patch("ragling.search.perform_batch_search", return_value=[[]]):
+            result = fn(queries=[{"query": "test"}])
+
+        assert result["indexing"] is not None
+        assert result["indexing"]["active"] is True
+        assert result["indexing"]["total_remaining"] == 3
+
+    def test_batch_search_idle_indexing_status(self, tmp_path: Path) -> None:
+        """Idle IndexingStatus (to_dict() returns None) must not crash."""
+        from ragling.indexing_status import IndexingStatus
+        from ragling.mcp_server import create_server
+
+        config = Config(
+            db_path=tmp_path / "test.db",
+            shared_db_path=tmp_path / "doc_store.sqlite",
+            embedding_dimensions=4,
+        )
+        status = IndexingStatus()  # idle â€” no pending work
+        server = create_server(config=config, indexing_status=status)
+        tools = server._tool_manager._tools
+        fn = tools["rag_batch_search"].fn
+
+        with patch("ragling.search.perform_batch_search", return_value=[[]]):
+            result = fn(queries=[{"query": "test"}])
+
+        assert result["indexing"] is None
+
diff --git a/tests/test_search.py b/tests/test_search.py
index eaf1bef..ab9dc17 100644
--- a/tests/test_search.py
+++ b/tests/test_search.py
@@ -10,7 +10,14 @@ from unittest.mock import MagicMock, patch
 import pytest
 
 from ragling.config import Config
-from ragling.search import SearchFilters, SearchResult, perform_search, rrf_merge
+from ragling.search import (
+    BatchQuery,
+    SearchFilters,
+    SearchResult,
+    perform_batch_search,
+    perform_search,
+    rrf_merge,
+)
 
 # Check if sqlite3 supports loading extensions (required for sqlite-vec integration tests)
 _conn = sqlite3.connect(":memory:")
@@ -1303,3 +1310,69 @@ class TestFtsSearchEmptyShortCircuit:
 
         assert result == []
         mock_conn.execute.assert_not_called()
+
+
+class TestPerformBatchSearch:
+    """Tests for perform_batch_search."""
+
+    @patch("ragling.search.get_embeddings", return_value=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])
+    @patch("ragling.search.get_connection")
+    @patch("ragling.search.init_db")
+    @patch("ragling.search.search", return_value=[])
+    def test_calls_search_for_each_query(self, mock_search, mock_init, mock_conn, mock_embed):
+        queries = [
+            BatchQuery(query="first"),
+            BatchQuery(query="second", collection="code", top_k=5),
+        ]
+        results = perform_batch_search(queries, config=Config(embedding_dimensions=4))
+        assert len(results) == 2
+        assert mock_search.call_count == 2
+
+    @patch("ragling.search.get_embeddings", return_value=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])
+    @patch("ragling.search.get_connection")
+    @patch("ragling.search.init_db")
+    @patch("ragling.search.search", return_value=[])
+    def test_uses_batch_embeddings(self, mock_search, mock_init, mock_conn, mock_embed):
+        """All query texts are embedded in a single batch call."""
+        queries = [
+            BatchQuery(query="alpha"),
+            BatchQuery(query="beta"),
+        ]
+        perform_batch_search(queries, config=Config(embedding_dimensions=4))
+        mock_embed.assert_called_once_with(["alpha", "beta"], mock_embed.call_args[0][1])
+
+    def test_empty_queries_returns_empty(self):
+        result = perform_batch_search([])
+        assert result == []
+
+    @patch("ragling.search.get_embeddings", return_value=[[1.0, 0.0, 0.0, 0.0]])
+    @patch("ragling.search.get_connection")
+    @patch("ragling.search.init_db")
+    @patch("ragling.search.search", return_value=[])
+    def test_passes_filters_per_query(self, mock_search, mock_init, mock_conn, mock_embed):
+        queries = [
+            BatchQuery(query="test", collection="obsidian", source_type="pdf"),
+        ]
+        perform_batch_search(queries, config=Config(embedding_dimensions=4))
+        call_args = mock_search.call_args
+        filters = call_args[0][4]  # 5th positional arg
+        assert filters.collection == "obsidian"
+        assert filters.source_type == "pdf"
+
+    @patch("ragling.search.get_embeddings", return_value=[[1.0, 0.0, 0.0]])
+    @patch("ragling.search.get_connection")
+    @patch("ragling.search.init_db")
+    def test_dimension_mismatch_raises(self, mock_init, mock_conn, mock_embed):
+        queries = [BatchQuery(query="test")]
+        with pytest.raises(ValueError, match="embedding dimension mismatch"):
+            perform_batch_search(queries, config=Config(embedding_dimensions=4))
+
+    @patch("ragling.search.get_embeddings", return_value=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0]])
+    @patch("ragling.search.get_connection")
+    @patch("ragling.search.init_db")
+    @patch("ragling.search.search", return_value=[])
+    def test_shares_single_connection(self, mock_search, mock_init, mock_conn, mock_embed):
+        """All queries use the same DB connection."""
+        queries = [BatchQuery(query="a"), BatchQuery(query="b")]
+        perform_batch_search(queries, config=Config(embedding_dimensions=4))
+        mock_conn.assert_called_once()  # Only one connection created
-- 
2.51.2

